{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "<center>\n    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-PY0101EN-SkillsNetwork/IDSNlogo.png\" width=\"300\" alt=\"cognitiveclass.ai logo\">\n</center>\n",
      "metadata": {
        "tags": [],
        "editable": true,
        "slideshow": {
          "slide_type": "slide"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "# Hands-on Lab: Working with different file formats\n\nEstimated time: **40 mins**\n",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true
      }
    },
    {
      "cell_type": "markdown",
      "source": "# Table of Contents\n\n<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n\n<font size = 3>\n\n1.  <a href=\"#Data-Engineering\">Data Engineering</a>\n2.  <a href=\"#Data-Engineering-Process\">Data Engineering Process</a>\n3.  <a href=\"#Working-with-different-file-formats\">Working with different file formats</a>\n4.  <a href=\"#Data-Analysis\">Data Analysis</a>\n\n</font>\n</div>\n",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true
      }
    },
    {
      "cell_type": "markdown",
      "source": "# Data Engineering\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "**Data engineering** is one of the most critical and foundational skills in any data scientistâ€™s toolkit.\n",
      "metadata": {
        "tags": [],
        "editable": true,
        "slideshow": {
          "slide_type": ""
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "# XML file format\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "**XML is also known as Extensible Markup Language**. As the name suggests, it is a markup language. It has certain rules for encoding data. XML file format is a human-readable and machine-readable file format.\n\nPandas does not include any methods to read and write XML files. Here, we will take a look at how we can use other modules to read data from an XML file, and load it into a Pandas DataFrame.\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### Writing with xml.etree.ElementTree\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "The **xml.etree.ElementTree** module comes built-in with Python. It provides functionality for parsing and creating XML documents. **ElementTree** represents the XML document as a tree. We can move across the document using nodes which are elements and sub-elements of the XML file.\n\nFor more information please read the [xml.etree.ElementTree](https://docs.python.org/3/library/xml.etree.elementtree.html?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkPY0101ENSkillsNetwork19487395-2021-01-01) documentation.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import xml.etree.ElementTree as ET\n\n# create the file structure\nemployee = ET.Element('employee')\ndetails = ET.SubElement(employee, 'details')\nfirst = ET.SubElement(details, 'firstname')\nsecond = ET.SubElement(details, 'lastname')\nthird = ET.SubElement(details, 'age')\nfirst.text = 'Shiv'\nsecond.text = 'Mishra'\nthird.text = '23'\n\n# create a new XML file with the results\nmydata1 = ET.ElementTree(employee)\n# myfile = open(\"items2.xml\", \"wb\")\n# myfile.write(mydata)\nwith open(\"new_sample.xml\", \"wb\") as files:\n    mydata1.write(files)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 25
    },
    {
      "cell_type": "markdown",
      "source": "### Reading with xml.etree.ElementTree\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Let's have a look at a one way to read XML data and put it in a Pandas DataFrame. You can see the XML file in the Notepad of your local machine.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Not needed unless running locally\n# !wget https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-PY0101EN-SkillsNetwork/labs/Module%205/data/Sample-employee-XML-file.xml\n\nimport xml.etree.ElementTree as etree\n\nfilename = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-PY0101EN-SkillsNetwork/labs/Module%205/data/Sample-employee-XML-file.xml\"\n\nasync def download(url, filename):\n    response = await pyfetch(url)\n    if response.status == 200:\n        with open(filename, \"wb\") as f:\n            f.write(await response.bytes())\n\nawait download(filename, \"Sample-employee-XML-file.xml\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 30
    },
    {
      "cell_type": "markdown",
      "source": "You would need to firstly parse an XML file and create a list of columns for data frame, then extract useful information from the XML file and add to a pandas data frame.\n\nHere is a sample code that you can use.:\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "tree = etree.parse(\"Sample-employee-XML-file.xml\")\n\nroot = tree.getroot()\ncolumns = [\"firstname\", \"lastname\", \"title\", \"division\", \"building\",\"room\"]\n\ndatatframe = pd.DataFrame(columns = columns)\n\nfor node in root: \n\n    firstname = node.find(\"firstname\").text\n\n    lastname = node.find(\"lastname\").text \n\n    title = node.find(\"title\").text \n    \n    division = node.find(\"division\").text \n    \n    building = node.find(\"building\").text\n    \n    room = node.find(\"room\").text\n    \n    datatframe = pd.concat([datatframe, pd.Series([firstname, lastname, title, division, building, room], index = columns)], ignore_index = True)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 31
    },
    {
      "cell_type": "code",
      "source": "datatframe",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "execution_count": 32,
          "output_type": "execute_result",
          "data": {
            "text/plain": "   firstname lastname title division building room          0\n0        NaN      NaN   NaN      NaN      NaN  NaN       Shiv\n1        NaN      NaN   NaN      NaN      NaN  NaN     Mishra\n2        NaN      NaN   NaN      NaN      NaN  NaN   Engineer\n3        NaN      NaN   NaN      NaN      NaN  NaN   Computer\n4        NaN      NaN   NaN      NaN      NaN  NaN        301\n5        NaN      NaN   NaN      NaN      NaN  NaN         11\n6        NaN      NaN   NaN      NaN      NaN  NaN        Yuh\n7        NaN      NaN   NaN      NaN      NaN  NaN      Datta\n8        NaN      NaN   NaN      NaN      NaN  NaN  developer\n9        NaN      NaN   NaN      NaN      NaN  NaN   Computer\n10       NaN      NaN   NaN      NaN      NaN  NaN        303\n11       NaN      NaN   NaN      NaN      NaN  NaN         02\n12       NaN      NaN   NaN      NaN      NaN  NaN      Rahil\n13       NaN      NaN   NaN      NaN      NaN  NaN       Khan\n14       NaN      NaN   NaN      NaN      NaN  NaN     Tester\n15       NaN      NaN   NaN      NaN      NaN  NaN   Computer\n16       NaN      NaN   NaN      NaN      NaN  NaN        304\n17       NaN      NaN   NaN      NaN      NaN  NaN         10\n18       NaN      NaN   NaN      NaN      NaN  NaN       Deep\n19       NaN      NaN   NaN      NaN      NaN  NaN     Parekh\n20       NaN      NaN   NaN      NaN      NaN  NaN   Designer\n21       NaN      NaN   NaN      NaN      NaN  NaN   Computer\n22       NaN      NaN   NaN      NaN      NaN  NaN        305\n23       NaN      NaN   NaN      NaN      NaN  NaN         14",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>firstname</th>\n      <th>lastname</th>\n      <th>title</th>\n      <th>division</th>\n      <th>building</th>\n      <th>room</th>\n      <th>0</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Shiv</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Mishra</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Engineer</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Computer</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>301</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Yuh</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Datta</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>developer</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Computer</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>303</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>02</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Rahil</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Khan</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Tester</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Computer</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>304</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Deep</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Parekh</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Designer</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Computer</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>305</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>14</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 32
    },
    {
      "cell_type": "markdown",
      "source": "### Reading xml  file using pandas.read_xml function\n\nWe can also read the downloaded xml file using the read_xml function present in the pandas library which returns a Dataframe object.\n\nFor more information read the <a href=\"https://pandas.pydata.org/pandas-docs/dev/reference/api/pandas.read_xml.html?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkPY0101ENSkillsNetwork19487395-2021-01-01#pandas-read-xml\">pandas.read_xml</a> documentation.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Herein xpath we mention the set of xml nodes to be considered for migrating  to the dataframe which in this case is details node under employees.\ndf=pd.read_xml(\"Sample-employee-XML-file.xml\", xpath=\"/employees/details\") ",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 33
    },
    {
      "cell_type": "markdown",
      "source": "### Save Data\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Correspondingly, Pandas enables us to save the dataset to csv by using the **dataframe.to_csv()** method, you can add the file path and name along with quotation marks in the parentheses.\n\nFor example, if you would save the dataframe df as **employee.csv** to your local machine, you may use the syntax below:\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "datatframe.to_csv(\"employee.csv\", index=False)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 34
    },
    {
      "cell_type": "markdown",
      "source": "We can also read and save other file formats, we can use similar functions to **`pd.read_csv()`** and **`df.to_csv()`** for other data formats. The functions are listed in the following table:\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "<h2>Read/Save Other Data Formats</h2>\n\n| Data Formate |        Read       |            Save |\n| ------------ | :---------------: | --------------: |\n| csv          |  `pd.read_csv()`  |   `df.to_csv()` |\n| json         |  `pd.read_json()` |  `df.to_json()` |\n| excel        | `pd.read_excel()` | `df.to_excel()` |\n| hdf          |  `pd.read_hdf()`  |   `df.to_hdf()` |\n| sql          |  `pd.read_sql()`  |   `df.to_sql()` |\n| ...          |        ...        |             ... |\n",
      "metadata": {}
    }
  ]
}